# Radar-Lidar Extrinsic Calibration

A Python implementation for performing extrinsic calibration between radar and lidar sensors using corner reflector correspondences. This project estimates the 3D rotation and translation between radar and lidar coordinate frames.

## ğŸ¯ Project Overview

This calibration system uses corner reflectors as common reference points to establish correspondences between radar and lidar measurements. The radar sensor has no elevation information, so the problem is simplified to 2D rigid transformation (rotation + translation in the XY plane).

## ğŸ“ Project Structure

```
calib_test/
â”œâ”€â”€ solve_calibration.py          # Main calibration algorithm
â”œâ”€â”€ quick_view.py                 # Interactive data visualization tool
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ test_data/                    # Sensor data (5 scenarios)
â”‚   â”œâ”€â”€ 8.csv, 8_rad.csv, 8.jpg  # Lidar, radar, camera data
â”‚   â”œâ”€â”€ 16.csv, 16_rad.csv, 16.jpg
â”‚   â”œâ”€â”€ 24.csv, 24_rad.csv, 24.jpg
â”‚   â”œâ”€â”€ 31.csv, 31_rad.csv, 31.jpg
â”‚   â””â”€â”€ 64.csv, 64_rad.csv, 64.jpg
â”œâ”€â”€ cfl_calibration.npz           # Camera calibration parameters
â”œâ”€â”€ lidar2cfl_new_all.npz         # Lidar-to-camera transformation
â”œâ”€â”€ point_matches_reflector/      # Generated: Corner reflector correspondences
â””â”€â”€ calibration_output/           # Generated: Calibration results and visualizations
```

## ğŸš€ Quick Start

### Option 1: Local Installation

#### Prerequisites

```bash
pip install numpy pandas scipy matplotlib opencv-python pillow tkinter
```

#### Running the Calibration

1. **Navigate to the project directory:**
   ```bash
   cd calib_test
   ```

2. **Run the calibration:**
   ```bash
   python solve_calibration.py
   ```

3. **View results:**
   - Check `calibration_output/` for generated visualizations
   - Use `quick_view.py` for interactive data exploration

### Option 2: Docker Container

#### Prerequisites

- Docker and Docker Compose installed
- For GUI applications: X11 server (Linux) or XQuartz (macOS)

#### Running with Docker

1. **Build and run the calibration:**
   ```bash
   docker compose up --build
   ```

2. **Run only the calibration (without GUI):**
   ```bash
   docker run --rm -v $(pwd)/calibration_output:/app/calibration_output -v $(pwd)/point_matches_reflector:/app/point_matches_reflector radar-lidar-calibration
   ```

3. **Run the interactive viewer:**
   ```bash
   docker compose --profile viewer up calibration-viewer
   ```

4. **View results:**
   - Check `calibration_output/` for generated visualizations
   - Results are automatically saved to your host machine

#### Docker Commands

```bash
# Build the image
docker build -t radar-lidar-calibration .

# Run calibration
docker run --rm -v $(pwd)/calibration_output:/app/calibration_output radar-lidar-calibration

# Run with interactive shell
docker run -it --rm -v $(pwd):/app radar-lidar-calibration bash

# Run viewer (requires X11 forwarding)
docker run --rm -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix -v $(pwd):/app radar-lidar-calibration python quick_view.py
```

#### Using the Docker Runner Script

For convenience, use the provided script:

```bash
# Make script executable (first time only)
chmod +x run_docker.sh

# Build and run calibration
./run_docker.sh build && ./run_docker.sh run

# Run interactive viewer
./run_docker.sh viewer

# Run with Docker Compose
./run_docker.sh compose

# Clean up Docker resources
./run_docker.sh clean

# Show help
./run_docker.sh help
```

## ğŸ”§ How It Works

### 1. Data Processing Pipeline

1. **Data Loading**: Load lidar and radar point clouds from CSV files
2. **Filtering**: Filter lidar points by z-coordinate (-1 to 2.5m) and range (2-30m)
3. **Correspondence Finding**: Use KD-Tree to find corner reflector correspondences
4. **Transformation Solving**: Apply Kabsch algorithm to find optimal transformation
5. **Validation**: Project results to camera images for visual verification

### 2. Corner Reflector Detection

For each image pair:
- Transform radar points to lidar frame using initial guess
- Build KD-Tree of filtered lidar points
- Find radar point with most nearby lidar points (corner reflector)
- Compute centroid of matched lidar cluster
- Establish correspondence: `(radar_point, lidar_centroid)`

### 3. Calibration Algorithms

The system implements three algorithms for 2D rigid transformation:

- **Kabsch Algorithm** (Default): Closed-form solution using SVD
- **ICP**: Iterative Closest Point for noisy data
- **RANSAC**: Robust estimation handling outliers

### 4. Coordinate Frames

```
Radar Frame â†’ Lidar Frame â†’ Camera Frame
     â†“            â†“            â†“
   R_RL, t_RL   R_LC, t_LC   Projection
```

## ğŸ“Š Output Files

### Generated Data
- **`point_matches_reflector/`**: Corner reflector correspondences
  - `lidar_points_X.npy`: Matched lidar points per image
  - `radar_points_X.npy`: Corresponding radar points per image

### Calibration Results
- **`calibration_output/radar_lidar_calibration.npz`**: Final transformation parameters
- **`calibration_output/radar_lidar_calibration_overview.png`**: Top-down visualization
- **`calibration_output/radar_lidar_projection_X.png`**: Camera projections for each image

## ğŸ® Interactive Visualization

Use the interactive viewer to explore the data:

```bash
python quick_view.py
```

**Controls:**
- **Arrow Keys**: Navigate between datasets
- **View**: Compare before/after calibration results

## âš™ï¸ Configuration

### Initial Parameters
The system uses initial transformation estimates:
- **Translation**: `[2.856, 0.635, -1.524]`
- **Rotation**: 50 degrees around Z-axis

### Filtering Parameters
- **Z-coordinate bounds**: -1.0 to 2.5 meters
- **Range bounds**: 2.0 to 30.0 meters
- **Correspondence radius**: 1.0 meters

## ğŸ” Algorithm Details

### Kabsch Algorithm
Minimizes the sum of squared distances between corresponding points:
```
minimize: Î£ || R * radar_point_i + t - lidar_centroid_i ||Â²
```

Where:
- **R**: 2Ã—2 rotation matrix
- **t**: 2D translation vector
- **i**: Index over all image pairs

### Data Flow
1. **Per-Image**: Compute lidar cluster centroids
2. **Overall**: Compute centroid of all centroids
3. **Kabsch**: Find optimal transformation aligning radar points with lidar centroids

## ğŸ“ˆ Performance

- **Processing Time**: ~2-3 seconds for 5 image pairs
- **Accuracy**: Sub-centimeter precision for well-calibrated sensors
- **Robustness**: Handles noise and outliers through filtering


## ğŸ› Troubleshooting

### Common Issues

1. **No correspondences found**
   - Check if corner reflector is visible in both sensors
   - Adjust filtering parameters
   - Verify initial transformation guess

2. **Poor calibration results**
   - Ensure corner reflector is stationary
   - Check for sensor synchronization issues
   - Try different initial parameters

3. **Visualization errors**
   - Verify camera calibration files exist
   - Check image file paths
   - Ensure OpenCV is properly installed

### Docker-Specific Issues

1. **GUI applications not working**
   - **Linux**: Install X11 server and run `xhost +local:docker`
   - **macOS**: Install XQuartz and run `xhost +localhost`
   - **Windows**: Use WSL2 with X11 forwarding

2. **Permission errors**
   - Ensure Docker has access to mounted volumes
   - Check file permissions on output directories
   - Run with `--user $(id -u):$(id -g)` for Linux

3. **Container build failures**
   - Check internet connection for package downloads
   - Verify Dockerfile syntax
   - Clear Docker cache: `docker system prune -a`

4. **Missing dependencies**
   - Update `requirements.txt` with missing packages
   - Rebuild container: `docker compose up --build --force-recreate`

## ğŸ“š References

- [Kabsch Algorithm](https://en.wikipedia.org/wiki/Kabsch_algorithm)
- [ICP Algorithm](https://en.wikipedia.org/wiki/Iterative_closest_point)
- [RANSAC Algorithm](https://en.wikipedia.org/wiki/Random_sample_consensus)
- [OpenCV Camera Calibration](https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html)

## ğŸ“„ License

This project is open source. Feel free to use and modify for your needs.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues, feature requests, or pull requests.

---

**Note**: This calibration system is designed for automotive sensor fusion applications where precise sensor alignment is critical for safety and performance.